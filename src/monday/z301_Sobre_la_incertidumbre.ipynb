{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNoCqM1I5-le"
   },
   "source": [
    "# Eligiendo modelos con incertidumbre\n",
    "\n",
    "> All models are wrong, but some are useful.\n",
    "\n",
    "George Box\n",
    "\n",
    "> If you torture the data long enough, it will confess.\n",
    "\n",
    "Ronald Coase\n",
    "\n",
    "A esta altura de la maetria, el alumno ya debe saber lo importante que es no sub-ajustar, ni sobre-ajustar un modelo. Puede repasar los conceptos visualmente en el siguiente link http://www.r2d3.us/visual-intro-to-machine-learning-part-2/\n",
    "\n",
    "Para lograr esto, necesitamos \"construir\" el mejor modelo posible. Sin embargo, esto nos plantea dos preguntas clave:\n",
    "* ¿qué significa construir un modelo?\n",
    "* Y, en segundo lugar, si tenemos dos modelos, ¿cómo determinamos cuál es el mejor?\n",
    "\n",
    "Empecemos realizando una comparación entre el modelo por defecto  de **árboles de decisión** (no controla el crecimiento) y uno levemente parametrizado.\n",
    "\n",
    "Levantemos el entorno e instalemos los paquetes que nos probablemente no dispongamos. Se usarán a lo largo de la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14392,
     "status": "ok",
     "timestamp": 1756154423254,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "oTlmka0Z7CA5",
    "outputId": "e1e2ac12-6737-4bf1-9e58-b9d7e66d7d7a"
   },
   "outputs": [],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1756154423278,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "x0IutZ5v4Pn5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,  _tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from time import time\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_param_importances, plot_contour,  plot_slice, plot_optimization_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgrO4dvN0jCI"
   },
   "source": [
    "Notará a continuación que trabajaremos como mes de entrenamiento **Febrero** y reservaremos **Abril** solo para pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21322,
     "status": "ok",
     "timestamp": 1756154457370,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "IbyPo4Dk4Mdh"
   },
   "outputs": [],
   "source": [
    "dataset_path = '/content/drive/MyDrive/DMEyF/2024/datos/'\n",
    "dataset_file = 'competencia_01.csv'\n",
    "\n",
    "ganancia_acierto = 780000\n",
    "costo_estimulo = 20000\n",
    "\n",
    "mes_train = 202102\n",
    "mes_test = 202104\n",
    "\n",
    "# agregue sus semillas\n",
    "semillas = [0, 1, 2, 3, 4]\n",
    "\n",
    "data = pd.read_csv(dataset_path + dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnYMoA1l4jJ3"
   },
   "outputs": [],
   "source": [
    "X = data[data['foto_mes'] == mes_train]\n",
    "y = X['clase_ternaria']\n",
    "X = X.drop(columns=['clase_ternaria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65j320lg1eth"
   },
   "source": [
    "Y necesitamos una función que nos ayude a calcular la ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWHFFm431krP"
   },
   "outputs": [],
   "source": [
    "def ganancia(model, X, y, prop=1, threshold=0.025):\n",
    "\n",
    "  class_index = np.where(model.classes_ == \"BAJA+2\")[0][0]\n",
    "  y_hat = model.predict_proba(X)\n",
    "\n",
    "  @np.vectorize\n",
    "  def ganancia_row(predicted, actual, threshold=0.025):\n",
    "    return  (predicted >= threshold) * (ganancia_acierto if actual == \"BAJA+2\" else -costo_estimulo)\n",
    "\n",
    "  return ganancia_row(y_hat[:,class_index], y).sum() / prop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjQM00zh3FtS"
   },
   "source": [
    "Mira a continuación el siguiente código.\n",
    "\n",
    "* ¿Cuál cree que es el mejor modelo?\n",
    "* ¿Cuáles son los problemas que ve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47673,
     "status": "ok",
     "timestamp": 1756152501652,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "t_vb-tye2dw_",
    "outputId": "d8e976ee-44c1-4b0d-bb2d-ac967544989d"
   },
   "outputs": [],
   "source": [
    "model_base = DecisionTreeClassifier(random_state=semillas[0])\n",
    "model_ale = DecisionTreeClassifier(criterion='gini',\n",
    "                               random_state=semillas[0],\n",
    "                               min_samples_split=80,\n",
    "                               max_depth=5)\n",
    "\n",
    "model_base.fit(X,y)\n",
    "model_ale.fit(X,y)\n",
    "\n",
    "print(f\"Ganancia de modelo Base: {ganancia(model_base, X, y)}\")\n",
    "print(f\"Ganancia de modelo Ale: {ganancia(model_ale, X, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxS0uXMz3PuY"
   },
   "source": [
    "* ¿Cómo se pueden solucionar?\n",
    "\n",
    "Dado que lo que hicimos no pinta nada bien, pasemos a una de las herramientas que separa la ciencia de datos de la estadística tradicional\n",
    "\n",
    "* ¿Por qué separamos en train/test?\n",
    "* ¿Cómo funciona la estadística tradicional?\n",
    "* Son números aleatorios los que nos dan las computadoras\n",
    "* ¿Por qué usamos semillas?\n",
    "* ¿Qué es una partición estratificada?\n",
    "* ¿Es realmente en nuestro caso una partición estratificada?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viSb47YW6jIK"
   },
   "source": [
    "Veamos alguna de las formas de separar los conjuntos de datos para medir su calidad:\n",
    "\n",
    "* **Train-Test Split**: Divide el conjunto de datos en dos partes: un conjunto de entrenamiento y otro de prueba. El conjunto de entrenamiento se utiliza para ajustar el modelo, y el conjunto de prueba para evaluar su rendimiento.\n",
    "\n",
    "* **K-Fold Cross Validation**: Divide los datos en k subconjuntos o folds. El modelo se entrena k veces, cada vez utilizando k-1 subconjuntos como entrenamiento y el subconjunto restante como prueba. Esto se repite hasta que cada subconjunto se haya utilizado como conjunto de prueba una vez.\n",
    "\n",
    "* **Shuffle Split** (aka Montecarlo Cross Validation): Genera múltiples particiones aleatorias de los datos en conjuntos de entrenamiento y prueba. A diferencia de K-Fold, no garantiza que todos los puntos de datos sean utilizados en alguna iteración.\n",
    "\n",
    "En la cátedra preferimos usar está última, pero el alumno es libre de usar la que considera conveniente.\n",
    "\n",
    "Armemos ahora nuevamente los modelos anteriores, pero utilizando estas particiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZGS36pPLM-O"
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=20,\n",
    "                             test_size=0.3,\n",
    "                             random_state=semillas[0])\n",
    "\n",
    "# Función que paraleliza la construcción de árboles de decisión\n",
    "def train_and_evaluate(train_index, test_index, params, X, y):\n",
    "  m = DecisionTreeClassifier(**params)\n",
    "  m.fit(X.iloc[train_index],y.iloc[train_index])\n",
    "  # Note que con el parámetro prop se corrige la distorsión por sampleo de la\n",
    "  # ganancia\n",
    "  ganancia_value = ganancia(m, X.iloc[test_index], y.iloc[test_index], prop=0.3)\n",
    "  return m, ganancia_value\n",
    "\n",
    "modelo_base_param = {\"random_state\":semillas[0]}\n",
    "\n",
    "modelo_ale_param = {\"criterion\": 'gini',\n",
    "                     \"random_state\":semillas[0],\n",
    "                     \"min_samples_split\":80,\n",
    "                     \"max_depth\":5,\n",
    "}\n",
    "\n",
    "results_base = Parallel(n_jobs=-1)(\n",
    "    delayed(train_and_evaluate)(train_index, test_index, modelo_base_param, X, y)\n",
    "    for train_index, test_index in sss.split(X, y)\n",
    ")\n",
    "\n",
    "results_ale = Parallel(n_jobs=-1)(\n",
    "    delayed(train_and_evaluate)(train_index, test_index, modelo_ale_param, X, y)\n",
    "    for train_index, test_index in sss.split(X, y)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICS3PBYI71h_"
   },
   "source": [
    "Estamos haciendo por cada juego de parámetros 20 modelos. Esto no suele ser lo habitual. Con 5 se puede conseguir buenos resultados.\n",
    "\n",
    "Vamos a ver que tan bien le fue a los modelos en los conjuntos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1756153312257,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "PxNSRwQT8-ZR",
    "outputId": "854556f2-3124-4528-b68c-5ab2e7b90ccc"
   },
   "outputs": [],
   "source": [
    "ganancias_modelos_base = [result[1] for result in results_base]\n",
    "ganancias_modelos_ale = [result[1] for result in results_ale]\n",
    "\n",
    "df_pred = pd.DataFrame({'Ganancia': [result[1] for result in results_base], 'Modelo': 'Base'})\n",
    "df_pred2 = pd.DataFrame({'Ganancia': [result[1] for result in results_ale], 'Modelo': 'Ale'})\n",
    "df_combined = pd.concat([df_pred, df_pred2])\n",
    "\n",
    "g = sns.FacetGrid(df_combined, row=\"Modelo\", aspect=2)\n",
    "g.map(sns.histplot, \"Ganancia\", kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI6se0-A-xsL"
   },
   "source": [
    "* ¿Qué tan distintos son de los primero valores calculados con el modelo completo?\n",
    "* ¿Con cuál se queda?\n",
    "* ¿Por qué se produce semejante dispersión?\n",
    "* ¿Cuál considera que es el \"valor real\"?\n",
    "\n",
    "Podemos mirar la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756153312258,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "weA6qiqe-FwA",
    "outputId": "e79f603b-b0fe-40c3-8cbb-29a296e5e8f2"
   },
   "outputs": [],
   "source": [
    "mean_base = df_combined[df_combined['Modelo'] == 'Base']['Ganancia'].mean()\n",
    "mean_ale = df_combined[df_combined['Modelo'] == 'Ale']['Ganancia'].mean()\n",
    "\n",
    "print(f\"Ganancia media del modelo base: {mean_base}\")\n",
    "print(f\"Ganancia media del modelo ale: {mean_ale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJatBPAU-67W"
   },
   "source": [
    "* Si no le gusta la media, como más puede elegir un modelo.\n",
    "\n",
    "> **La vida no es simple**  -- Alumno promedio de la maestría.\n",
    "\n",
    "Muy interesante, pero lo importante es que sucedería en el **futuro**. Por este motivo nos guardamos el mes de **Abril**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjooaKLHXkko"
   },
   "outputs": [],
   "source": [
    "X_futuro = data[data['foto_mes'] == mes_test]\n",
    "y_futuro = X_futuro['clase_ternaria']\n",
    "X_futuro = X_futuro.drop(columns=['clase_ternaria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsUTeSfM_goB"
   },
   "source": [
    "Sobre el mes de abril, debemos usar el modelo que se entreno sobre todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1756153312748,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "h4FixjUZ7owV",
    "outputId": "3b497e5a-4c6f-4993-ee1e-9995a2fb25e0"
   },
   "outputs": [],
   "source": [
    "ganancia_junio_base = ganancia(model_base, X_futuro, y_futuro)\n",
    "ganancia_junio_ale = ganancia(model_ale, X_futuro, y_futuro)\n",
    "\n",
    "print(f\"Ganancia de modelo Base en Junio: {ganancia_junio_base}\")\n",
    "print(f\"Ganancia de modelo Ale en Junio: {ganancia_junio_ale}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQM8zroBBTjG"
   },
   "source": [
    "* ¿Cuál es mejor?\n",
    "* ¿Por qué cree que el mejor es el mejor?\n",
    "* ¿Hubiera elegido sabiamente únicamente con los datos de **Febrero**?\n",
    "\n",
    "El mundo es un lugar **cruel** para los data scientists. El escenario anterior tampoco es el presente para los alumnos. Ya que **kaggle** divide el dataset en una parte **pública** y otra **privada**. Simulemos los efectos que produce en la decisión del mejor modelo en los leaderboards, simulando varios a la vez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QoUgUIam8ASR"
   },
   "outputs": [],
   "source": [
    "# podemos tomar más muestras, dado que solo vamos a scorear y eso es más rápido\n",
    "sss_futuro = StratifiedShuffleSplit(n_splits=50,\n",
    "                             test_size=0.3,\n",
    "                             random_state=semillas[0])\n",
    "\n",
    "ganancias_futuro_privada_ale = []\n",
    "ganancias_futuro_privada_base = []\n",
    "ganancias_futuro_publica_ale = []\n",
    "ganancias_futuro_publica_base = []\n",
    "\n",
    "for train_index, test_index in sss_futuro.split(X_futuro, y_futuro):\n",
    "  ganancias_futuro_privada_ale.append(ganancia(model_ale, X_futuro.iloc[train_index], y_futuro.iloc[train_index], prop=0.7))\n",
    "  ganancias_futuro_privada_base.append(ganancia(model_base, X_futuro.iloc[train_index], y_futuro.iloc[train_index], prop=0.7))\n",
    "  ganancias_futuro_publica_ale.append(ganancia(model_ale, X_futuro.iloc[test_index], y_futuro.iloc[test_index], prop=0.3))\n",
    "  ganancias_futuro_publica_base.append(ganancia(model_base, X_futuro.iloc[test_index], y_futuro.iloc[test_index], prop=0.3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 1485,
     "status": "ok",
     "timestamp": 1756153352192,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "4UTGsLzKE5vQ",
    "outputId": "3570a350-5f47-422a-9caf-34b9bf2a1d29"
   },
   "outputs": [],
   "source": [
    "df_pred_1_ale = pd.DataFrame({'Ganancia': ganancias_futuro_privada_ale, 'Modelo': 'ale', 'Grupo': 'Privado'})\n",
    "df_pred_2_ale = pd.DataFrame({'Ganancia': ganancias_futuro_publica_ale, 'Modelo': 'ale', 'Grupo': 'Publico'})\n",
    "df_pred_1_base = pd.DataFrame({'Ganancia': ganancias_futuro_privada_base, 'Modelo': 'Base', 'Grupo': 'Privado'})\n",
    "df_pred_2_base = pd.DataFrame({'Ganancia': ganancias_futuro_publica_base, 'Modelo': 'Base', 'Grupo': 'Publico'})\n",
    "\n",
    "df_combined = pd.concat([df_pred_1_base, df_pred_2_base, df_pred_1_ale, df_pred_2_ale ])\n",
    "\n",
    "g = sns.FacetGrid(df_combined, col=\"Grupo\", row=\"Modelo\", aspect=2)\n",
    "g.map(sns.histplot, \"Ganancia\", kde=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756153352192,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "0p7Po1I7FlL6",
    "outputId": "e68566cc-6cdf-46be-e3cf-58c2a2643de4"
   },
   "outputs": [],
   "source": [
    "mean_base_privado = df_combined[(df_combined['Modelo'] == 'Base') & (df_combined['Grupo'] == 'Privado')]['Ganancia'].mean()\n",
    "mean_base_publico = df_combined[(df_combined['Modelo'] == 'Base') & (df_combined['Grupo'] == 'Publico')]['Ganancia'].mean()\n",
    "mean_ale_privado = df_combined[(df_combined['Modelo'] == 'ale') & (df_combined['Grupo'] == 'Privado')]['Ganancia'].mean()\n",
    "mean_ale_publico = df_combined[(df_combined['Modelo'] == 'ale') & (df_combined['Grupo'] == 'Publico')]['Ganancia'].mean()\n",
    "\n",
    "print(f\"Ganancia media del modelo base en privado: {mean_base_privado}\")\n",
    "print(f\"Ganancia media del modelo base en publico: {mean_base_publico}\")\n",
    "print(f\"Ganancia media del modelo ale en privado: {mean_ale_privado}\")\n",
    "print(f\"Ganancia media del modelo ale en publico: {mean_ale_publico}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw0NeIfOG77K"
   },
   "source": [
    "* ¿Que significa todo esto?\n",
    "\n",
    "Bueno, dos cosas.\n",
    "\n",
    "* El modelo ale, es un caso de **vagancia**. Cambiar 2 parámetros y esperar un cambio radical no es lo más inteligente que se puede hacer. Realmente hay que hacer un esfuerzo para separar las distribuciones.\n",
    "* Aún así elegir un modelo no es una tarea simple que se pueda hacer con una **certeza** absoluta.\n",
    "\n",
    "Para mejorar los modelos, una paso adecuado es la búsqueda de hiperparámetros. Podemos contar con las siguientes técnicas de búsqueda de parámetros:\n",
    "\n",
    "* **Grid Search**: Explora exhaustivamente todas las combinaciones posibles de hiperparámetros dentro de un conjunto predefinido de valores. Aunque es exhaustivo.\n",
    "\n",
    "* **Random Search**: En lugar de probar todas las combinaciones posibles, selecciona un número aleatorio de combinaciones de hiperparámetros dentro de un rango predefinido.\n",
    "\n",
    "* **Bayesian Optimization**: Este método construye un modelo probabilístico del rendimiento de los hiperparámetros y utiliza ese modelo para seleccionar los valores de hiperparámetros más prometedores.\n",
    "\n",
    "* **Tree-structured Parzen Estimator (TPE)**: Una variante de la optimización bayesiana que utiliza estimadores de densidad basados en árboles (Parzen estimators) para modelar la probabilidad de los hiperparámetros óptimos. Es eficiente en la exploración de espacios de hiperparámetros complejos y se adapta bien a configuraciones con interdependencias entre los parámetros.\n",
    "\n",
    "* **Genetic Algorithms**: Emplea principios de la evolución natural, como selección, cruce y mutación, para encontrar combinaciones óptimas de hiperparámetros. Es útil en espacios de búsqueda complejos, aunque puede ser computacionalmente costoso.\n",
    "\n",
    "Repasemos en clase de que se trata cada uno. (tome notas)\n",
    "\n",
    "Todos nos buenas opciones para la búsqueda de ... nah mentira, **grid search** apesta, si no me cree calcule el tiempo necesario para barrer el dominio de búsqueda.\n",
    "\n",
    "Para la búsquedas de parámetros usaremos **Optuna**. **Optuna** es una librería poderosa y flexible, diseñada para realizar búsquedas eficientes y automatizadas.\n",
    "\n",
    "* Utiliza casi todos los álgoritmos mencionados y más.\n",
    "\n",
    "* Permite definir espacios de búsqueda complejos, incluyendo hiperparámetros categóricos, continuos, discretos y con dependencias condicionales.\n",
    "\n",
    "* Ofrece un mecanismo de pruning o poda, que permite detener evaluaciones de configuraciones de hiperparámetros que no muestran promesas tempranas.\n",
    "\n",
    "* Facilidad de Uso y Configuración.\n",
    "\n",
    "* Proporciona herramientas de visualización integradas para analizar el progreso de la optimización, visualizar la importancia de los hiperparámetros y explorar las configuraciones probadas.\n",
    "\n",
    "Buscaremos un mejor modelo de manera inteligente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1070,
     "status": "ok",
     "timestamp": 1756154485445,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "85WbW6qroyfn",
    "outputId": "2277d434-f4cf-49f7-8f94-2ae30819a5ff"
   },
   "outputs": [],
   "source": [
    "\n",
    "sss_opt = ShuffleSplit(n_splits=5, test_size=0.3, random_state=semillas[1])\n",
    "\n",
    "def objective(trial, X, y, sss):\n",
    "  criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "  max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "  min_samples_split = trial.suggest_int('min_samples_split', 2, 200)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "  max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 2, 20)\n",
    "\n",
    "  def train_and_evaluate(train_index, test_index, X, y):\n",
    "    m = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "        random_state=semillas[0],\n",
    "    )\n",
    "    m.fit(X.iloc[train_index],y.iloc[train_index])\n",
    "    ganancia_value = ganancia(m, X.iloc[test_index], y.iloc[test_index], prop=0.3)\n",
    "    return ganancia_value\n",
    "\n",
    "  results = Parallel(n_jobs=-1)(\n",
    "      delayed(train_and_evaluate)(train_index, test_index, X, y)\n",
    "      for train_index, test_index in sss.split(X)\n",
    "  )\n",
    "\n",
    "  return np.mean(results)\n",
    "\n",
    "storage_name = \"sqlite:////content/drive/MyDrive/Datos/optimization_tree.db\"\n",
    "study_name = \"exp_101_decision-tree-opt\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pLQD79dbP9P"
   },
   "source": [
    "Entre la muchas ventajas que tiene **Optuna** es que va almacenando las exploraciones en una base de datos, lo que nos permite continuar la búsqueda si esta se interrumpe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2656571,
     "status": "ok",
     "timestamp": 1756157165375,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "Ba56plD9bLup",
    "outputId": "1397baa5-de08-468b-b2f8-f21c3ea4898f"
   },
   "outputs": [],
   "source": [
    "# No quiero que se ejecute automaticamente\n",
    "study.optimize(lambda trial: objective(trial, X, y, sss_opt), n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KM8WsVYMcE6M"
   },
   "source": [
    "A continuación veremos como fue el proceso de búsqueda a través de las visualizaciones que cuenta la herramienta (los gráficos son bastante autoexplicativos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1756157165859,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "wJ9-4XqG64AD",
    "outputId": "670ed9ca-6f61-4d1a-95b9-53c36985a7e0"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 703,
     "status": "ok",
     "timestamp": 1756157166571,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "C4o1mz-b53_Q",
    "outputId": "fc2c73da-8394-4be6-f4b4-81b857b3f016"
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1756157166933,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "XhcFEzRB62J2",
    "outputId": "acf83e4a-68d0-4c5c-f885-182e1afe57a0"
   },
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1756157167575,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "ZXGkSPR46pzy",
    "outputId": "d13a8015-1cd6-4037-bf25-0bc1403a44ae"
   },
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1756157167587,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "KIu_VjPn-LrW",
    "outputId": "d4e450cf-bc47-420d-dd0d-b3299e709404"
   },
   "outputs": [],
   "source": [
    "plot_contour(study, params=[\"max_depth\", \"max_leaf_nodes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYy1gCarctOm"
   },
   "source": [
    "Pasemos a analizar como le fue al mejor modelo en **Abril**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10572,
     "status": "ok",
     "timestamp": 1756157178159,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "qX8GEf5M7aH1",
    "outputId": "98873d24-c3e7-442a-915c-3d3f6f9730ad"
   },
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo\n",
    "best_trial = study.best_trial\n",
    "best_model_params = best_trial.params\n",
    "print(\"Mejor modelo:\", best_model_params)\n",
    "\n",
    "model_best = DecisionTreeClassifier(**best_model_params, random_state=semillas[0])\n",
    "model_best.fit(X, y)\n",
    "\n",
    "print(f\"Ganancia del mejor modelo: {ganancia(model_best, X_futuro, y_futuro)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yK8LBJVeD8R"
   },
   "source": [
    "Es mejor que los anteriores! y solo por una hora de procesamiento!!!\n",
    "\n",
    "¿qué más podemos pedir por tan poco?\n",
    "\n",
    "Veamos comparados con los anteriores que tanto mejor es...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "executionInfo": {
     "elapsed": 22382,
     "status": "ok",
     "timestamp": 1756157200544,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "kRWjXvFWTTdL",
    "outputId": "d55c55a0-58a8-4ebd-c218-b76484b5cb82"
   },
   "outputs": [],
   "source": [
    "ganancias_futuro_top0_publica = []\n",
    "ganancias_futuro_top0_privado = []\n",
    "for train_index, test_index in sss_futuro.split(X_futuro, y_futuro):\n",
    "  ganancias_futuro_top0_publica.append(ganancia(model_best, X_futuro.iloc[test_index], y_futuro.iloc[test_index], prop=0.3))\n",
    "  ganancias_futuro_top0_privado.append(ganancia(model_best, X_futuro.iloc[train_index], y_futuro.iloc[train_index], prop=0.7))\n",
    "\n",
    "df_pred_top0_privado = pd.DataFrame({'Ganancia': ganancias_futuro_top0_privado, 'Modelo': 'top0', 'Grupo': 'Privado'})\n",
    "df_pred_top0_publica = pd.DataFrame({'Ganancia': ganancias_futuro_top0_publica, 'Modelo': 'top0', 'Grupo': 'Publico'})\n",
    "\n",
    "df_combined = pd.concat([df_pred_1_base,\n",
    "                         df_pred_2_base,\n",
    "                         df_pred_1_ale,\n",
    "                         df_pred_2_ale,\n",
    "                         df_pred_top0_privado,\n",
    "                         df_pred_top0_publica])\n",
    "\n",
    "g = sns.FacetGrid(df_combined, col=\"Grupo\", row=\"Modelo\", aspect=2)\n",
    "g.map(sns.histplot, \"Ganancia\", kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djfNrxaXeaMa"
   },
   "source": [
    "Bueno, no parece mucho mejor. Es tan solo mejor. Vamos moviendo de a poco la vara.\n",
    "\n",
    "* ¿Qué se puede hacer para mejorarlo? Debate con la clase abierta\n",
    "\n",
    "Una última cosa, solo de pura maldad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28500,
     "status": "ok",
     "timestamp": 1756157229043,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "jZ7r-UOgSw58",
    "outputId": "d04f26d1-03c4-4e2f-cb2a-a7731d3deebf"
   },
   "outputs": [],
   "source": [
    "n_top_models = 3\n",
    "top_trials = study.best_trials[0:n_top_models]\n",
    "\n",
    "top_models = []\n",
    "for i, trial in enumerate(top_trials):\n",
    "     model_params = trial.params\n",
    "     print(f\"Top {i}: {model_params}\")\n",
    "     model = DecisionTreeClassifier(**model_params, random_state=semillas[0])\n",
    "     model.fit(X, y)\n",
    "     top_models.append(model)\n",
    "\n",
    "ganancias_abril = []\n",
    "for model in top_models:\n",
    "  ganancias_abril.append(ganancia(model, X_futuro, y_futuro))\n",
    "\n",
    "for i, ganancia_abril in enumerate(ganancias_abril):\n",
    "  print(f\"Ganancia de top {i} en abril: {ganancia_abril}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gk_3Fuly0vmI"
   },
   "source": [
    "## Tarea:\n",
    "\n",
    "* Envíos a Kaggle:\n",
    " * Defina los mejores parámetros para realizar una búsqueda.\n",
    " * Explore la configuración de Optuna para una mejor búsqueda.\n",
    " * Arme un script que tome la salida de un modelo y genere un archivo para Kaggle.\n",
    " * Entrena el modelo usando datos de febrero y mirando su rendimiento en abril.  \n",
    "   * Prueba el modelo completo entrenado en febrero, score en Junio y suba a  Kaggle.\n",
    "   * El modelo seleccionado se reentrena con los datos de abril y se scorea en junio para kaggle\n",
    "* Busca el mejor modelo en abril y scoree en junio para Kaggle.\n",
    "\n",
    "¿Cuál fue su mejor predicción?\n",
    "\n",
    "Colaboración:\n",
    "* Recuerde compartir con tus compañeros los nuevos scripts que hayas generado y las configuraciones que hayas probado por el canal de"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
