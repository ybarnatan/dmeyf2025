{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNoCqM1I5-le"
      },
      "source": [
        "# Fuego contra Fuego\n",
        "\n",
        "> Fuego contra fuego es amar.\n",
        "\n",
        "Ricky Martin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0X0atYk2Bqf"
      },
      "source": [
        "Instalamos, cargamos y seteamos el entorno\n",
        "Si generamos un error, lo solucionamos sacando las versiones especificas mencionadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sc7PN8Rw2Xz-"
      },
      "outputs": [],
      "source": [
        "#%pip install scikit-learn==1.3.2\n",
        "#%pip install seaborn==0.13.1\n",
        "#%pip install numpy==1.26.4\n",
        "#%pip install matplotlib==3.7.1\n",
        "%pip install optuna==3.6.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0IutZ5v4Pn5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree,  _tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "import optuna\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
        "\n",
        "from time import time\n",
        "\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbyPo4Dk4Mdh"
      },
      "outputs": [],
      "source": [
        "#Modificar segun la estructura de sus carpetas, no se olviden crear las que faltan\n",
        "base_path = '/content/drive/MyDrive/DMEyF/2024/'\n",
        "dataset_path = base_path + 'datos/'\n",
        "modelos_path = base_path + 'modelos/'\n",
        "db_path = base_path + 'db/'\n",
        "dataset_file = 'competencia_01.csv'\n",
        "\n",
        "ganancia_acierto = 780000\n",
        "costo_estimulo = 20000\n",
        "\n",
        "mes_train = 202102\n",
        "mes_test = 202104\n",
        "\n",
        "# agregue sus semillas\n",
        "semillas = [17,19,23,29,31]\n",
        "\n",
        "data = pd.read_csv(dataset_path + dataset_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ4tmVzq45TQ"
      },
      "source": [
        "Seguimos trabajando con Febrero como entrenamiento y Abril como test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnYMoA1l4jJ3"
      },
      "outputs": [],
      "source": [
        "X = data[data['foto_mes'] == mes_train]\n",
        "y = X['clase_ternaria']\n",
        "X = X.drop(columns=['clase_ternaria'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjooaKLHXkko"
      },
      "outputs": [],
      "source": [
        "X_futuro = data[data['foto_mes'] == mes_test]\n",
        "y_futuro = X_futuro['clase_ternaria']\n",
        "X_futuro = X_futuro.drop(columns=['clase_ternaria'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUzMp4eW5BMU"
      },
      "source": [
        "Y variaremos la forma de la función de ganancia, para poder ser utilizada de una forma más genérica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWHFFm431krP"
      },
      "outputs": [],
      "source": [
        "def ganancia_prob(y_hat, y, prop=1, class_index=1, threshold=0.025):\n",
        "  @np.vectorize\n",
        "  def ganancia_row(predicted, actual, threshold=0.025):\n",
        "    return  (predicted >= threshold) * (ganancia_acierto if actual == \"BAJA+2\" else -costo_estimulo)\n",
        "\n",
        "  return ganancia_row(y_hat[:,class_index], y).sum() / prop\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjQM00zh3FtS"
      },
      "source": [
        "Ajustamos los modelos de la clase pasada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "t_vb-tye2dw_",
        "outputId": "93f906af-26d5-47bc-aabb-9c3c30c3aeba"
      },
      "outputs": [],
      "source": [
        "param_ale = {'max_depth': 5,\n",
        "             'min_samples_split': 80}\n",
        "\n",
        "param_opt = {'criterion': 'entropy',\n",
        "             'max_depth': 20,\n",
        "             'min_samples_split': 145,\n",
        "             'min_samples_leaf': 14,\n",
        "             'max_leaf_nodes': 13}\n",
        "\n",
        "model_base = DecisionTreeClassifier(random_state=semillas[0])\n",
        "model_ale = DecisionTreeClassifier(random_state=semillas[0], **param_ale)\n",
        "model_opt = DecisionTreeClassifier(random_state=semillas[0], **param_opt)\n",
        "\n",
        "model_base.fit(X, y)\n",
        "model_ale.fit(X, y)\n",
        "model_opt.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRv4M8t7tEuG"
      },
      "outputs": [],
      "source": [
        "y_pred_base = model_base.predict_proba(X_futuro)\n",
        "y_pred_ale = model_ale.predict_proba(X_futuro)\n",
        "y_pred_opt = model_opt.predict_proba(X_futuro)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82XTLehP5pnI"
      },
      "source": [
        "Recordemos la ganancia de cada uno en Abril"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwtpzQ9_YwVX",
        "outputId": "85dcc0bc-efce-4d26-8106-08b9d030bd80"
      },
      "outputs": [],
      "source": [
        "print(f\"Ganancia de modelo Base: {ganancia_prob(y_pred_base, y_futuro)}\")\n",
        "print(f\"Ganancia de modelo Ale: {ganancia_prob(y_pred_ale, y_futuro)}\")\n",
        "print(f\"Ganancia de modelo Opt: {ganancia_prob(y_pred_opt, y_futuro)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVKR6iHd52oG"
      },
      "source": [
        "Antes de continuar con nuestro camino de estrés y sumeración, analizaremos que tan bien hubieramos elegido un modelo de acuerdo a utilizar un leaderboard público. Primero comparamos el **base** y el **ale**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPQZ3bUw6nHP"
      },
      "outputs": [],
      "source": [
        "sss_futuro = StratifiedShuffleSplit(n_splits=50,\n",
        "                             test_size=0.3,\n",
        "                             random_state=semillas[0])\n",
        "modelos = {\"base\": y_pred_base, \"ale\": y_pred_ale}\n",
        "rows = []\n",
        "for private_index, public_index in sss_futuro.split(X_futuro, y_futuro):\n",
        "  row = {}\n",
        "  for name, y_pred in modelos.items():\n",
        "    row[name + \"_private\"] = ganancia_prob(y_pred[private_index], y_futuro.iloc[private_index], 0.7)\n",
        "    row[name + \"_public\"] = ganancia_prob(y_pred[public_index], y_futuro.iloc[public_index], 0.3)\n",
        "  rows.append(row)\n",
        "df_lb = pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1UBiW0v7k2u"
      },
      "source": [
        "Una forma de ver si una distribución es distinta a otra es usar el test de wilcoxon. Este test se usa para determinar si hay una diferencia significativa en las medianas de dos muestras dependientes.\n",
        "\n",
        "Lo vamos a aplicar sobre nuestro simulado leaderboard público con la esperanza que nos ayude a eligir cual de los dos es mejor, para esa muestra.\n",
        "\n",
        "(Recuerde, no se esta aplicando al Leaderboard público real. Técnicamente estamos aplicandolo a un out of time sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHaNM7gI7J80",
        "outputId": "400abcc3-6eba-4e97-e91d-26eacdbd1fe0"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import wilcoxon\n",
        "\n",
        "diff_public = df_lb['base_public'] - df_lb['ale_public']\n",
        "_, p_value = wilcoxon(diff_public)\n",
        "\n",
        "print(f\"p-value: {p_value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvcEILhV8owt"
      },
      "source": [
        "Espero que sus recuerdos traumaticos de estadísticas le ayuden a leer que la prueba plantea que ambas distribuciones son lo diferentes, y **ale** es mayor.\n",
        "\n",
        "Veremos con el privado que tan bien nos hubiera ido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMIrb6GnsQp_"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "\n",
        "df['best_public'] = df_lb.filter(regex='_public').idxmax(axis=1)\n",
        "df['best_private'] = df_lb.filter(regex='_private').idxmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "W15p4Vk-60Bz",
        "outputId": "0ca0a0a1-3d29-4195-a553-075c1ff6e1fe"
      },
      "outputs": [],
      "source": [
        "pd.crosstab(df['best_public'], df['best_private'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4xo7BGp-ryv"
      },
      "source": [
        "Sus opiniones. Volvemos al panic de la clase pasada, no? Vamos a agregar el modelo optimizado a la comparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXXXtCDO-CUX"
      },
      "outputs": [],
      "source": [
        "sss_futuro = StratifiedShuffleSplit(n_splits=50,\n",
        "                             test_size=0.3,\n",
        "                             random_state=semillas[0])\n",
        "modelos = {\"opt\":y_pred_opt}\n",
        "rows = []\n",
        "for private_index, public_index in sss_futuro.split(X_futuro, y_futuro):\n",
        "  row = {}\n",
        "  for name, y_pred in modelos.items():\n",
        "    row[name + \"_private\"] = ganancia_prob(y_pred[private_index], y_futuro.iloc[private_index], 0.7)\n",
        "    row[name + \"_public\"] = ganancia_prob(y_pred[public_index], y_futuro.iloc[public_index], 0.3)\n",
        "  rows.append(row)\n",
        "df_temp = pd.DataFrame(rows)\n",
        "df_lb = pd.concat([df_lb, df_temp], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "9BXPMzfzvWvE",
        "outputId": "01d4c154-f0a5-4695-a1d7-a4e13e89e114"
      },
      "outputs": [],
      "source": [
        "df['best_public'] = df_lb.filter(regex='_public').idxmax(axis=1)\n",
        "df['best_private'] = df_lb.filter(regex='_private').idxmax(axis=1)\n",
        "\n",
        "pd.crosstab(df['best_public'], df['best_private'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSb930s_BBcm"
      },
      "source": [
        "Sus reflexiones.\n",
        "\n",
        "---\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "---\n",
        "\n",
        "Creo que necesitamos algo superador. Para eso nos abrazaremos al problema, todo el daño que produce el azar, será la luz que resuelva nuestro problema.\n",
        "\n",
        "Primero hablamos de ensemables, qué son?\n",
        "\n",
        "* Un ensemble de modelos es una técnica donde se combinan múltiples modelos individuales para mejorar la precisión y robustez de las predicciones. La idea es que al combinar varios modelos, se pueden aprovechar las fortalezas de cada uno y reducir la posibilidad de errores que podría cometer un único modelo.\n",
        "\n",
        "* **Tipos de ensemble**:\n",
        " * **Bagging (Bootstrap Aggregating)**: Consiste en entrenar varios modelos base en diferentes subconjuntos del conjunto de datos de entrenamiento obtenidos mediante técnicas de remuestreo como el bootstrap y luego promediar sus predicciones. Ejemplo: **Random Forest**\n",
        " * **Boosting**: En esta técnica, los modelos se entrenan de manera secuencial. Cada modelo intenta corregir los errores cometidos por el modelo anterior. Ejemplo: AdaBoost y **Gradient Boosting**.\n",
        " * **Stacking**: En el stacking, se entrenan varios modelos y se combinan usando un \"modelo meta\". Las predicciones de los modelos base sirven como features para entrenar este modelo meta, que produce la predicción final.\n",
        "\n",
        "* **Ventajas de usar ensemble de modelos**:\n",
        " * **Mejor rendimiento**: Al combinar modelos, generalmente se mejora la precisión en comparación con un solo modelo.\n",
        " * **Robustez**: Al integrar diferentes modelos, se mitiga el riesgo de que los errores de un modelo individual afecten gravemente la predicción final.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8LGmmP7Cr33"
      },
      "source": [
        "Pongamos foco en el **Random Forest**\n",
        "\n",
        "Es un algoritmo de aprendizaje automático que funciona creando un conjunto de árboles de decisión. Para la creación de **árboles distintos** utiliza una técnica llamada bagging para crear múltiples subconjuntos del conjunto de datos de entrenamiento. Cada subconjunto se genera seleccionando al azar muestras del conjunto de datos original con reemplazo. No usa la totalidad de los datos de entrenamiento para cada conjunto. Los datos que quedan fueran son conocidos como **Out of Bag (oob)**\n",
        "\n",
        "Para cada subconjunto, se construye un árbol de decisión. Sin embargo en cada nodo del árbol, **Random Forest** selecciona de forma aleatoria un grupo de variables y ajusta el árbol con esas variables. Este proceso ayuda a crear árboles que son menos correlacionados entre sí.\n",
        "\n",
        "Cada árbol en el bosque se entrena de manera independiente usando su respectivo subconjunto de datos. Lueago, para una nueva observación, cada árbol realiza una predicción. El Random Forest luego combina las predicciones de todos los árboles para hacer una predicción final, devolviendo el promedio de las probabilidades de cada árbol individual.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCz2C0wWEA0y"
      },
      "source": [
        "Como desde la clase pasada solo personas más inteligentes, no vamos a empezar a probar **Random Forest** simples. Vamos a parametrizarlo desde el vamos.\n",
        "\n",
        "Primero vamos a entender algunas limitaciones de la implementación:\n",
        "\n",
        "El **Random Forest** no soporta nulos! Shame on you sklearn!.\n",
        "\n",
        "Vamos a tener que imputar los datos. Discutamos entre todos forma de imputar los datos, mientras para salir del paso usamos la peor de todas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge2QADE-ZYiA"
      },
      "outputs": [],
      "source": [
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "Xi = imp_mean.fit_transform(X)\n",
        "Xif = imp_mean.fit_transform(X_futuro)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qt-gCWzHJqk"
      },
      "source": [
        "Los parámetros que se pueden ajustar en el **rf** son\n",
        "\n",
        "1. **n_estimators**: Número de árboles en el bosque.\n",
        "2. **max_depth**: Profundidad máxima de los árboles.\n",
        "3. **min_samples_split**: Número mínimo de muestras requeridas para dividir un nodo interno.\n",
        "4. **min_samples_leaf**: Número mínimo de muestras requeridas para estar en un nodo hoja.\n",
        "5. **max_features**: Número de features a usar en cada árbol. **sqrt** es una elección histórica.\n",
        "6. **max_leaf_nodes**: Número máximo de nodos hoja en cada árbol.\n",
        "7. **oob_score**: Indica si se usa la muestra fuera de bolsa (out-of-bag) para estimar la calidad del modelo. Para evitar hacer un **montecarlo-cross-validation** que se toma su tiempo, usaremos esta opción para buscar el mejor modelo. No es la mejor opción. Pero no es tan mala.\n",
        "8. **n_jobs**: Siempre -1, para que use todos los cores presentes en 9. **max_samples**: Fracción de los samples.\n",
        "\n",
        "Finalmente nuestra función de optimización queda la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxpOCJhSBVfR",
        "outputId": "ec435c23-b9cc-4b19-fa7e-c81441803a52"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 2000)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 200)\n",
        "    max_features = trial.suggest_float('max_features', 0.05, 0.7)\n",
        "\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features,\n",
        "        max_samples=0.7,\n",
        "        random_state=semillas[0],\n",
        "        n_jobs=-1,\n",
        "        oob_score=True\n",
        "    )\n",
        "\n",
        "    model.fit(Xi, y)\n",
        "\n",
        "    return ganancia_prob(model.oob_decision_function_, y)\n",
        "\n",
        "storage_name = \"sqlite:///\" + db_path + \"optimization_tree.db\"\n",
        "study_name = \"exp_206_random-forest-opt\"\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    study_name=study_name,\n",
        "    storage=storage_name,\n",
        "    load_if_exists=True,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v42RWy_rGLOb",
        "outputId": "ba181b33-7318-4651-8b77-f5887c03bfbc"
      },
      "outputs": [],
      "source": [
        "# study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3EbXtH5LSKg"
      },
      "source": [
        "Exploramos como fue la búsqueda de parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "wJ9-4XqG64AD",
        "outputId": "850ec7a3-343a-4f6f-dda3-bdb113a9a60d"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "C4o1mz-b53_Q",
        "outputId": "f1fae43f-99e1-4c72-f883-59182eb9db39"
      },
      "outputs": [],
      "source": [
        "plot_param_importances(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "XhcFEzRB62J2",
        "outputId": "a20a67d6-926e-4397-d2ba-059027ced680"
      },
      "outputs": [],
      "source": [
        "plot_slice(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ZXGkSPR46pzy",
        "outputId": "6a3f3cf3-1d45-419b-be8b-db1564339997"
      },
      "outputs": [],
      "source": [
        "plot_contour(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "KIu_VjPn-LrW",
        "outputId": "c27be5e1-513e-4de5-95bc-fd58d57a5d47"
      },
      "outputs": [],
      "source": [
        "plot_contour(study, params=[\"max_depth\", \"min_samples_split\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mby34hbrK7y7"
      },
      "source": [
        "Ajustamos el mejor modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExNBUAIFIjdW"
      },
      "outputs": [],
      "source": [
        "model_rf = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        **study.best_params,\n",
        "        max_samples=0.7,\n",
        "        random_state=semillas[0],\n",
        "        n_jobs=-1,\n",
        "        oob_score=True\n",
        "    )\n",
        "\n",
        "# model_rf.fit(Xi, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcM_E4HGJpOG"
      },
      "source": [
        "Guardamos el modelo, para no tener que optimizar cada vez que lo queramos usar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsbiVkfvttKz"
      },
      "outputs": [],
      "source": [
        "filename = modelos_path + 'exp_206_random_forest_model_100.sav'\n",
        "# pickle.dump(model_rf, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csG99V1TMLMx"
      },
      "source": [
        "Y lo cargamos para utilizarlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "iKN3AQGyMU5o",
        "outputId": "565c278a-8fb9-4645-b627-97bc99e9ece2"
      },
      "outputs": [],
      "source": [
        "model_rf = pickle.load(open(filename, 'rb'))\n",
        "model_rf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKKLgLIOMfTX"
      },
      "source": [
        "Ahora vamos medir su ganancia sobre el dataset de **abril**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fB9TXuWcrXH",
        "outputId": "234d003e-25f7-4f59-c3fe-3e8a9647e078"
      },
      "outputs": [],
      "source": [
        "y_pred_rf = model_rf.predict_proba(Xif)\n",
        "ganancias_rf = ganancia_prob(y_pred_rf, y_futuro)\n",
        "print(f\"Ganancia de modelo RF: {ganancias_rf}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46jjCmNsNBM8"
      },
      "source": [
        "What!? Qué paso? que son esos números???\n",
        "\n",
        "Algo malo que hicimos, es usar poquitos estimadores. Tan solo unos 100. Suficientes como para que la optimización no tarde una eternidad, pero es muy poco. Deberíamos sumar unos cuantos más."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "qz2um7ceNVV-",
        "outputId": "1b8bcffd-27c6-4eeb-a80e-2ee167a05fba"
      },
      "outputs": [],
      "source": [
        "model_rf_1000 = RandomForestClassifier(\n",
        "        n_estimators=1000,\n",
        "        **study.best_params,\n",
        "        max_samples=0.7,\n",
        "        random_state=semillas[0],\n",
        "        n_jobs=-1,\n",
        "        oob_score=True\n",
        "    )\n",
        "\n",
        "# model_rf_1000.fit(Xi, y)\n",
        "\n",
        "filename_rf_1000 = modelos_path + 'exp_206_random_forest_model_1000.sav'\n",
        "# pickle.dump(model_rf, open(filename_rf_1000, 'wb'))\n",
        "\n",
        "model_rf_1000 = pickle.load(open(filename_rf_1000, 'rb'))\n",
        "model_rf_1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H5zjt94Nnh-"
      },
      "source": [
        "Veamos si sumar 10 veces más estimadores tuvo algún efecto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ-v-6kdqVP0",
        "outputId": "474a11fb-ab67-4d31-a713-f0707ba187c2"
      },
      "outputs": [],
      "source": [
        "y_pred_rf = model_rf_1000.predict_proba(Xif)\n",
        "ganancias_rf = ganancia_prob(y_pred_rf, y_futuro)\n",
        "print(f\"Ganancia de modelo RF 1000: {ganancias_rf}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqpngFlKN7KW"
      },
      "source": [
        "Mejoró! Cada peso vale.\n",
        "\n",
        "Sin embargo, es este modelo tan superior o será ese número lindo.\n",
        "\n",
        "Calculemos su impacto en los leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1mh6X-UPPnK"
      },
      "outputs": [],
      "source": [
        "sss_futuro = StratifiedShuffleSplit(n_splits=50,\n",
        "                             test_size=0.3,\n",
        "                             random_state=semillas[0])\n",
        "modelos = {\"rf\":y_pred_rf}\n",
        "rows = []\n",
        "for private_index, public_index in sss_futuro.split(X_futuro, y_futuro):\n",
        "  row = {}\n",
        "  for name, y_pred in modelos.items():\n",
        "    row[name + \"_private\"] = ganancia_prob(y_pred[private_index], y_futuro.iloc[private_index], 0.7)\n",
        "    row[name + \"_public\"] = ganancia_prob(y_pred[public_index], y_futuro.iloc[public_index], 0.3)\n",
        "  rows.append(row)\n",
        "df_temp = pd.DataFrame(rows)\n",
        "df_lb = pd.concat([df_lb, df_temp], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "7yidoVzkPSbC",
        "outputId": "eddac019-57b8-4e5a-d4ae-628d4a645e6a"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "df['best_public'] = df_lb.filter(regex='_public').idxmax(axis=1)\n",
        "df['best_private'] = df_lb.filter(regex='_private').idxmax(axis=1)\n",
        "\n",
        "pd.crosstab(df['best_public'], df['best_private'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzAIAXUFP0gK"
      },
      "source": [
        "Vaya! es lo que buscabamos, un modelo del que estar seguros. Podrémos ver esto en los histogramas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXpNgTYRQBCI"
      },
      "outputs": [],
      "source": [
        "df_lb_long = df_lb.reset_index()\n",
        "df_lb_long = df_lb_long.melt(id_vars=['index'], var_name='model_type', value_name='ganancia')\n",
        "df_lb_long[['modelo', 'tipo']] = df_lb_long['model_type'].str.split('_', expand=True)\n",
        "df_lb_long = df_lb_long[['ganancia', 'tipo', 'modelo']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7-QnDP-9QV34",
        "outputId": "a2aaf59d-7939-4fba-bcca-3f0725bdb381"
      },
      "outputs": [],
      "source": [
        "g = sns.FacetGrid(df_lb_long, col=\"tipo\", row=\"modelo\", aspect=2)\n",
        "g.map(sns.histplot, \"ganancia\", kde=True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjuPtCOdRh31"
      },
      "source": [
        "Por último evaluamos cuales son las variables más importantes del modelo. ¿Habrá influido la imputación?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "3_uHQFFPRXKj",
        "outputId": "b82ea343-4c46-451a-9cc7-75def2812970"
      },
      "outputs": [],
      "source": [
        "importances = model_rf.feature_importances_\n",
        "\n",
        "features = X.columns\n",
        "feat_importances = pd.DataFrame({'feature': features, 'importance': importances})\n",
        "feat_importances = feat_importances.sort_values('importance', ascending=False)\n",
        "\n",
        "feat_importances.head(25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk_3Fuly0vmI"
      },
      "source": [
        "Felicitaciones! ahora sabe como superar un **árbol de decisión**.\n",
        "\n",
        "Pregunta:\n",
        "* **¿Cómo sabe que un random forest es superior a otro?**\n",
        "* **¿Cómo supera el random forest presentado?**\n",
        "\n",
        "## Tarea:\n",
        "\n",
        "* Envíe a modelo de **rf** a Kaggle\n",
        "* Mejore la parametrización del **rf**\n",
        "* Juegue un poco:\n",
        " * Borre la variable más importante y mida el **rf**.\n",
        " * Agregue variables 100% aleatorias. ¿Salen dentro de las variables más importante?\n",
        " * No probamos en **rf** en el mismo dataset de entrenamiento. ¿Se puede decir que sobre ajusta?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
